{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "04921720",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--path PATH] [--train_ratio TRAIN_RATIO]\n",
      "                             [--n_res N_RES] [--density DENSITY]\n",
      "                             [--spectral_radius SPECTRAL_RADIUS]\n",
      "                             [--alpha ALPHA] [--input_scale INPUT_SCALE]\n",
      "                             [--reg REG] [--washout WASHOUT]\n",
      "                             [--loss_chunk LOSS_CHUNK] [--include_input]\n",
      "                             [--seed SEED]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: --f=/run/user/1000/jupyter/runtime/kernel-v305735bf60fd897666dca71068bd5cf1a2f6bd4e2.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/medlar/Projects/EvoReservoir/.venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py:3587: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "# esn_char_predict.py\n",
    "# Echo State Network for next-character prediction on tinyshakespear.txt\n",
    "# - Chronological train/test split\n",
    "# - Online RLS readout training (memory efficient)\n",
    "# - Reports test accuracy and plots training loss over time\n",
    "\n",
    "import argparse\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def build_vocab(text):\n",
    "    chars = sorted(list(set(text)))\n",
    "    stoi = {ch: i for i, ch in enumerate(chars)}\n",
    "    itos = {i: ch for ch, i in stoi.items()}\n",
    "    return chars, stoi, itos\n",
    "\n",
    "def text_to_indices(text, stoi):\n",
    "    return np.array([stoi[ch] for ch in text], dtype=np.int32)\n",
    "\n",
    "def init_reservoir(n_in, n_res, density, spectral_radius, input_scale, seed):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    # Input weights include bias; shape: n_res x (1 + n_in)\n",
    "    Win = (rng.standard_normal((n_res, 1 + n_in)).astype(np.float32)) * input_scale\n",
    "    # Reservoir weights sparse-ish dense matrix\n",
    "    W = np.zeros((n_res, n_res), dtype=np.float32)\n",
    "    nnz = int(density * n_res * n_res)\n",
    "    idx_i = rng.integers(0, n_res, size=nnz)\n",
    "    idx_j = rng.integers(0, n_res, size=nnz)\n",
    "    vals = rng.standard_normal(nnz).astype(np.float32)\n",
    "    W[idx_i, idx_j] = vals\n",
    "    # Scale to desired spectral radius\n",
    "    eigvals = np.linalg.eigvals(W.astype(np.float64))\n",
    "    sr = np.max(np.abs(eigvals)).real\n",
    "    if sr > 0:\n",
    "        W *= (spectral_radius / sr)\n",
    "    return Win, W\n",
    "\n",
    "def rls_init(n_feat, reg):\n",
    "    # P ~ (1/reg) * I; larger 1/reg means weaker prior (more plastic)\n",
    "    P = (1.0 / reg) * np.eye(n_feat, dtype=np.float32)\n",
    "    return P\n",
    "\n",
    "def run_esn_training(\n",
    "    indices,\n",
    "    vocab_size,\n",
    "    Win, W,\n",
    "    alpha=0.3,\n",
    "    washout=100,\n",
    "    reg=1.0,\n",
    "    loss_chunk=1000,\n",
    "    include_input_in_readout=True,\n",
    "    seed=42,\n",
    "):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    n_res = W.shape[0]\n",
    "    n_in = vocab_size\n",
    "    n_out = vocab_size\n",
    "\n",
    "    # One-hot lookup\n",
    "    I = np.eye(vocab_size, dtype=np.float32)\n",
    "\n",
    "    # Reservoir state\n",
    "    x = np.zeros(n_res, dtype=np.float32)\n",
    "\n",
    "    # Feature vector z = [1, u, x] or [1, x]\n",
    "    if include_input_in_readout:\n",
    "        n_feat = 1 + n_in + n_res\n",
    "    else:\n",
    "        n_feat = 1 + n_res\n",
    "\n",
    "    # Readout\n",
    "    Wout = np.zeros((n_out, n_feat), dtype=np.float32)\n",
    "\n",
    "    # RLS inverse correlation matrix\n",
    "    P = rls_init(n_feat, reg=reg)\n",
    "\n",
    "    # Loss tracking\n",
    "    losses = []\n",
    "    chunk_losses = []\n",
    "    steps_seen = 0\n",
    "\n",
    "    # Training loop (teacher forcing), using all pairs (t -> t+1) after washout\n",
    "    # We will update P and Wout only after washout\n",
    "    T = len(indices) - 1\n",
    "    bias = np.array([1.0], dtype=np.float32)\n",
    "\n",
    "    for t in range(T):\n",
    "        u_idx = indices[t]\n",
    "        v_idx = indices[t + 1]\n",
    "\n",
    "        u = I[u_idx]  # one-hot current\n",
    "        v = I[v_idx]  # one-hot next\n",
    "\n",
    "        # Reservoir update: x <- (1 - alpha) * x + alpha * tanh( Win @ [1; u] + W @ x )\n",
    "        in_vec = np.concatenate([bias, u], dtype=np.float32)  # shape 1 + n_in\n",
    "        preact = Win @ in_vec + W @ x\n",
    "        x = (1.0 - alpha) * x + alpha * np.tanh(preact)\n",
    "\n",
    "        # Feature vector\n",
    "        if include_input_in_readout:\n",
    "            z = np.concatenate([bias, u, x], dtype=np.float32)  # shape n_feat\n",
    "        else:\n",
    "            z = np.concatenate([bias, x], dtype=np.float32)\n",
    "\n",
    "        # Predict\n",
    "        y_pred = Wout @ z  # linear logits for each char\n",
    "\n",
    "        # Compute MSE loss vs one-hot target\n",
    "        err = v - y_pred\n",
    "        mse = np.mean(err * err)\n",
    "        # During washout, just track reservoir settling; no RLS updates\n",
    "        if t >= washout:\n",
    "            # RLS update\n",
    "            # k = P z / (1 + z^T P z)\n",
    "            Pz = P @ z\n",
    "            denom = 1.0 + float(z @ Pz)\n",
    "            k = Pz / denom  # shape (n_feat,)\n",
    "\n",
    "            # Wout <- Wout + (v - y_pred) k^T\n",
    "            # Broadcasting outer product for multi-output\n",
    "            Wout += np.outer(err, k).astype(np.float32)\n",
    "\n",
    "            # P <- P - k (z^T P)\n",
    "            P -= np.outer(k, Pz).astype(np.float32)\n",
    "\n",
    "            # record loss\n",
    "            chunk_losses.append(mse)\n",
    "            steps_seen += 1\n",
    "            if steps_seen % loss_chunk == 0:\n",
    "                losses.append(float(np.mean(chunk_losses)))\n",
    "                chunk_losses = []\n",
    "\n",
    "    # If last partial chunk exists, record it\n",
    "    if len(chunk_losses) > 0:\n",
    "        losses.append(float(np.mean(chunk_losses)))\n",
    "\n",
    "    return Wout, losses\n",
    "\n",
    "def evaluate_accuracy(indices, vocab_size, Win, W, Wout, alpha=0.3, include_input_in_readout=True):\n",
    "    # Teacher forcing evaluation: predict next char from current char and current state\n",
    "    n_res = W.shape[0]\n",
    "    I = np.eye(vocab_size, dtype=np.float32)\n",
    "    x = np.zeros(n_res, dtype=np.float32)\n",
    "    bias = np.array([1.0], dtype=np.float32)\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    T = len(indices) - 1\n",
    "    for t in range(T):\n",
    "        u_idx = indices[t]\n",
    "        v_idx = indices[t + 1]\n",
    "        u = I[u_idx]\n",
    "\n",
    "        in_vec = np.concatenate([bias, u], dtype=np.float32)\n",
    "        preact = Win @ in_vec + W @ x\n",
    "        x = (1.0 - alpha) * x + alpha * np.tanh(preact)\n",
    "\n",
    "        if include_input_in_readout:\n",
    "            z = np.concatenate([bias, u, x], dtype=np.float32)\n",
    "        else:\n",
    "            z = np.concatenate([bias, x], dtype=np.float32)\n",
    "\n",
    "        y_pred = Wout @ z\n",
    "        pred_idx = int(np.argmax(y_pred))\n",
    "        correct += (pred_idx == v_idx)\n",
    "        total += 1\n",
    "    acc = correct / total if total > 0 else 0.0\n",
    "    return acc\n",
    "\n",
    "def main():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--path\", type=str, default=\"tinyshakespeare.txt\", help=\"Path to text file\")\n",
    "    parser.add_argument(\"--train_ratio\", type=float, default=0.9, help=\"Chronological train split ratio\")\n",
    "    parser.add_argument(\"--n_res\", type=int, default=300, help=\"Reservoir size\")\n",
    "    parser.add_argument(\"--density\", type=float, default=0.05, help=\"Reservoir connection density in [0,1]\")\n",
    "    parser.add_argument(\"--spectral_radius\", type=float, default=0.9, help=\"Reservoir spectral radius\")\n",
    "    parser.add_argument(\"--alpha\", type=float, default=0.3, help=\"Leaking rate\")\n",
    "    parser.add_argument(\"--input_scale\", type=float, default=1.0, help=\"Scale for input weights\")\n",
    "    parser.add_argument(\"--reg\", type=float, default=1.0, help=\"RLS regularization (P0 = I/reg)\")\n",
    "    parser.add_argument(\"--washout\", type=int, default=100, help=\"Washout steps during training\")\n",
    "    parser.add_argument(\"--loss_chunk\", type=int, default=2000, help=\"Steps per averaged loss point\")\n",
    "    parser.add_argument(\"--include_input\", action=\"store_true\", help=\"Include direct input-to-readout in features\")\n",
    "    parser.add_argument(\"--seed\", type=int, default=42, help=\"Random seed\")\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    # Load text\n",
    "    with open(args.path, \"r\", encoding=\"utf-8\") as f:\n",
    "        text = f.read()\n",
    "\n",
    "    # Build vocab and indices\n",
    "    chars, stoi, itos = build_vocab(text)\n",
    "    data = text_to_indices(text, stoi)\n",
    "    vocab_size = len(chars)\n",
    "    N = len(data)\n",
    "\n",
    "    # Chronological split\n",
    "    split = int(args.train_ratio * N)\n",
    "    train_idx = data[:split]\n",
    "    test_idx  = data[split:]\n",
    "\n",
    "    print(f\"Text length: {N}, Vocab size: {vocab_size}\")\n",
    "    print(f\"Train steps: {len(train_idx)-1}, Test steps: {len(test_idx)-1}\")\n",
    "\n",
    "    # Initialize reservoir\n",
    "    Win, W = init_reservoir(\n",
    "        n_in=vocab_size,\n",
    "        n_res=args.n_res,\n",
    "        density=args.density,\n",
    "        spectral_radius=args.spectral_radius,\n",
    "        input_scale=args.input_scale,\n",
    "        seed=args.seed,\n",
    "    )\n",
    "\n",
    "    # Train (RLS online)\n",
    "    Wout, losses = run_esn_training(\n",
    "        train_idx,\n",
    "        vocab_size,\n",
    "        Win, W,\n",
    "        alpha=args.alpha,\n",
    "        washout=args.washout,\n",
    "        reg=args.reg,\n",
    "        loss_chunk=args.loss_chunk,\n",
    "        include_input_in_readout=args.include_input,\n",
    "        seed=args.seed,\n",
    "    )\n",
    "\n",
    "    # Evaluate accuracy on test set\n",
    "    test_acc = evaluate_accuracy(\n",
    "        test_idx,\n",
    "        vocab_size,\n",
    "        Win, W, Wout,\n",
    "        alpha=args.alpha,\n",
    "        include_input_in_readout=args.include_input,\n",
    "    )\n",
    "\n",
    "    print(f\"Test accuracy (next-char, teacher forcing): {test_acc:.4f}\")\n",
    "\n",
    "    # Plot training loss\n",
    "    plt.figure(figsize=(8,4))\n",
    "    xs = np.arange(1, len(losses)+1) * args.loss_chunk\n",
    "    plt.plot(xs, losses, label=\"Training MSE (avg per chunk)\")\n",
    "    plt.xlabel(\"Training steps\")\n",
    "    plt.ylabel(\"MSE\")\n",
    "    plt.title(\"ESN Readout Online Training Loss (RLS)\")\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"training_loss.png\", dpi=150)\n",
    "    try:\n",
    "        plt.show()\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
